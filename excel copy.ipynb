{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "DATA_DIR = './test'\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "number_of_classes = 2 #assuming you have 26 classes\n",
    "dataset_size = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip running below code if test data already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    #if not cap,isOpened():\n",
    "    #printf(\"Error:Could not open camera.\")\n",
    "    #exit()\n",
    "\n",
    "    for j in range(number_of_classes):\n",
    "        if not os.path.exists(os.path.join(DATA_DIR, str(j))):\n",
    "            os.makedirs(os.path.join(DATA_DIR,str(j)))\n",
    "\n",
    "        print('Collecting data for class{}'.format(j))\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            cv2.putText(frame, 'Ready? Press \"S\" to start capturing, \"N\" to skip, or \"q\" to exit!', (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1.0,(0,255,0),3, cv2.LINE_AA)\n",
    "            cv2.imshow('frame', frame)\n",
    "            key = cv2.waitKey(25)\n",
    "\n",
    "            if key == ord('s'):\n",
    "                print(\"Capturing data for class{}\".format(j))\n",
    "                break\n",
    "            elif key == ord('n'):\n",
    "                print(\"Capturing data for class{}\".format(j))\n",
    "                break\n",
    "            elif key == ord('q'):\n",
    "                print(\"Exiting the program.\")\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "        if key == ord('n'):\n",
    "            continue #Skip to the next class\n",
    "\n",
    "        counter = 0\n",
    "        while counter < dataset_size:\n",
    "            ret, frame = cap.read()\n",
    "            cv2.imshow('frame', frame)\n",
    "            cv2.waitKey(25)\n",
    "            cv2.imwrite(os.path.join(DATA_DIR, str(j), '{}.jpg'.format(counter)),frame)\n",
    "            counter += 1\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # for directory operations\n",
    "import pickle # This module implements binary protocol for serializing and de-serializing Python onjects. It's used for saving and loading objects to/from files.\n",
    "\n",
    "import mediapipe as mp #\n",
    "import cv2 #\n",
    "import matplotlib.pyplot as plt # for plotting images\n",
    "\n",
    "# Load the hand tracking model\n",
    "mp_hands = mp.solutions.hands # for hand tracking\n",
    "mp_drawing = mp.solutions.drawing_utils # for drawing Landmarks\n",
    "mp_drawing_styles = mp.solutions.drawing_styles # for drawing styles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#static image mode is used for processing a single image. min_detection_confidence is the minimum confidence value ([0.0, 1.0]) for the hand detection to be considered successfully.\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Raw image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dir_ \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[43mDATA_DIR\u001b[49m):  \u001b[38;5;66;03m#Loop through the classes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR, dir_))[:\u001b[38;5;241m1\u001b[39m]: \u001b[38;5;66;03m#Loop through the images\u001b[39;00m\n\u001b[0;32m      3\u001b[0m         img\u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR, dir_, img_path)) \u001b[38;5;66;03m#read the image    \u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DATA_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "for dir_ in os.listdir(DATA_DIR):  #Loop through the classes\n",
    "    for img_path in os.listdir(os.path.join(DATA_DIR, dir_))[:1]: #Loop through the images\n",
    "        img= cv2.imread(os.path.join(DATA_DIR, dir_, img_path)) #read the image    \n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #convert the image to RGB\n",
    "\n",
    "        plt.figure()  #create a new figure\n",
    "        plt.imshow(img_rgb)  #display the image\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Annotated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the Land marks on the image (only last frame \"Just for Understanding\")\n",
    "\n",
    "DATA_DIR = './test' # path to the data directory\n",
    "\n",
    "for dir_ in os.listdir(DATA_DIR): # Loop through the classes\n",
    "    for img_path in os.listdir(os.path.join(DATA_DIR, dir_))[:1]: # loop through the Images\n",
    "        img = cv2.imread(os.path.join(DATA_DIR, dir_, img_path)) # read the image    \n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # convert the image to RGB\n",
    "\n",
    "        results = hands.process(img_rgb) # this will process the image and return the Landmarks\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hands_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(img_rgb, # image to draw \n",
    "                                          hands_landmarks, # model output \n",
    "                                          mp_hands.HAND_CONNECTIONS, # hand connections \n",
    "                                          mp_drawing_styles.get_default_hand_landmarks_style(), # drawing styles \n",
    "                                          mp_drawing_styles.get_default_hand_connections_style()) # drawing styles\n",
    "\n",
    "\n",
    "        plt.figure() # create a new figure\n",
    "        plt.imshow(img_rgb) # display the image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR ='./test' # path to the test directory\n",
    "\n",
    "# Create empty lists to store the data and Labels \n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for dir_ in os.listdir(DATA_DIR): # Loop through the classes\n",
    "    for img_path in os.listdir(os.path.join(DATA_DIR, dir_)): # Loop through the images\n",
    "        data_aux = [] # create a empty list to store the landmark\n",
    "\n",
    "        x_ = [] # create an empty list to store the x coordinate\n",
    "        y_ = [] # create an empty list to store the y coordinate\n",
    "\n",
    "        img = cv2.imread(os.path.join(DATA_DIR, dir_, img_path)) # read the image\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # convert the image to RGB\n",
    "\n",
    "        results = hands.process(img_rgb) # this will process the image and return the Landmarks\n",
    "\n",
    "        if  results.multi_hand_landmarks: # if there are hands in image\n",
    "            for hand_landmarks in results.multi_hand_landmarks: # loop through the hands\n",
    "                for i in range(len(hand_landmarks.landmark)): #loop through the Landmark\n",
    "                    x = hand_landmarks.landmark[i].x # x coordinate to the X_list\n",
    "                    y = hand_landmarks.landmark[i].y # y coordinate to the y_list\n",
    "\n",
    "                    x_.append(x) # append the x coordinate to the X_list\n",
    "                    y_.append(y) # append the y coordinate to the y_list\n",
    "\n",
    "                for i in range(len(hand_landmarks.landmark)): # loop through the landmark\n",
    "                    x = hand_landmarks.landmark[i].x # x coordinate of the landmark\n",
    "                    y = hand_landmarks.landmark[i].y # y coordinate of the landmark\n",
    "                    data_aux.append(x - min(x_)) # append the normalized x coordinate to the data_aux list\n",
    "                    data_aux.append(y - min(y_)) # append the normalized y coordinate to the data_aux list\n",
    "\n",
    "            data.append(data_aux) # append the data_aux list to the data list\n",
    "            labels.append(dir_) # append the label to the labels list\n",
    "\n",
    "f = open ('test.pickle', 'wb') # open a file in binary write mode\n",
    "pickle.dump({'data': data, 'labels': labels}, f) # save the data and labels to yhe file\n",
    "f.close() # close the file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirmation [Recomended to include only two classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of classes [do only for 2 classes]\n",
    "dir_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are 42 floating point numbers for each img. This is because we have 21 landmarks and each landmark has an x and y coordinate. We can reshape the data to have 21 rows and 2 columns\n",
    "#data_aux hold the data for the last img from the lastclasses\n",
    "data_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data from pickle file and confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "datafrompickle = pd.read_pickle('test.pickle') #read the data from the pickle file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label represent the classes\n",
    "\n",
    "print(datafrompickle['labels'][0:200]) #start from 0 to 100 labels not including 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datafrompickle['labels'][100:200]) #get the labels from index 100 till 200 (not include 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing end of the list\n",
    "print(datafrompickle['labels'][199]) # since only 2 classes,we have 0th label for 0th class and 1st label for 1st class totally 200 labels only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = datafrompickle['labels'][100:200] #get the labels from the index 100 till 200 (not include 200)\n",
    "# example list\n",
    "# count the number of ones\n",
    "num_ones = list.count('1')\n",
    "print(\"Number of ones in the list:\",num_ones,\"--> hence each class has 100 image and each are labelled correctly\") # print the number of ones in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data\n",
    "print(datafrompickle['data'][0:199]) #dispaly the first 200 rows of the data because we collected 100 images for each class and if we have 2 classes then we have 200 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the stored data with the original data\n",
    "#data is original data before dumping to pickle\n",
    "#datadrompickle is data after loading from pickle\n",
    "\n",
    "if datafrompickle['data'][199] == data_aux:\n",
    "    print('the data is the same as the original data')\n",
    "else:\n",
    "    print('the data is not the same as the original data')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load the data from the pickle file\n",
    "data_from_pickle = pd.read_pickle('test.pickle')\n",
    "\n",
    "#create a data from the data\n",
    "df = pd.DataFrame(data_from_pickle['data'], columns=[f'x_{i}' for i in range(21)] + [f'y_{i}' for i in range(21)])\n",
    "\n",
    "#add the label column to the dataframe\n",
    "df['label'] = data_from_pickle['labels']\n",
    "\n",
    "#save the dataframe to an excel file\n",
    "df.to_excel('data.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delete1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
